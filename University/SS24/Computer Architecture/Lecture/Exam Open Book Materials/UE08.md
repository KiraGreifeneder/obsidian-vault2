![[../../UEs/_attachments/Pasted image 20240630223027.png]]
## Aufgabe 1
## a) CPI und Ausführungszeit
> For the CPI (avg. number of cycles per instruction), we look at the number of requred cycles for each operation and multiply it by its probability
> For the Execution Time, we multiply the instruction count, CPI, and the clock fperiod (Taktperiode = t/taktfrequenz)
### Single-cycle Prozessor
Since everything takes one cycle here, the CPI is 1.
Ausführungszeit $T^A_{exe}=I_c*CPI*T$
Taktfrquenz  $f = 700Mhz = 700 * 10^6 Hz$
Taktperiode $T =1/700*10^6 = 1.42857*10^{-9}s = 1.42857ns$
$T^{A}_{exe}=3Mrd. * ~1 * 1.42857ns = 4285710000ns = 4285710000 * 10^{-9} = 4.28571s$
### Multicycle Prozessor
$CPI = \sum\limits^n_{i=1}(CPI_i*F_i)$
$CPI = 0.42 * 4 + 0.12*5 + 0.21 * 3 + 0.07 * 4 + 0.18 * 4 =3.91$
$T = \frac{1}{3.4*10^9}s$
$T^{A}_{exe}=3Mrd. * ~3.91 * \frac{1}{3.4*10^9} = 3.45s$
### Pipelined Prozessor
In this case, we'll just calculate the total number of cycles we need
- We have a baseline of needing at 3 billion cycles + 4 cycles where no instructions are completed due to the processor not being full yet.
- Additionally some cycles will be incurred through jumps and NOPs (or similar):
	- $Cycles_{jal, beq}=(3B * (0.21*0.32+0.18)) * 2 = 1483200000$ additional cycles, because for each jump two cycles are flushed
	- $Cycles_{NOP} = (3B * 0.42) * 0.25 = 315000000$ because for every 4th arithmetic operation, we lose a cycle 

With that, out CPI is the total number of cycles divided by the number of instructions...:
$CPI = (3B + 4 + 1483200000 + 315000000)/(3B) = 1.5994$ cycles per instruction

Funky things to remember for pipelined processors:
- Technically, most operations only require one cycle (as we read in a new instruction with each cycle and at the same time an instruction is completing every cycle)
- However, in the beginning, no instructions haven't been read in yet and we have 5 cycles where no instruction is being completed
- When we have to jump in the execute phase, we also have to cancel the instructions that were read in while all the branch/jump stuff was being processed, thereby "losing" two cycles. So these instructions sometimes take up two cycles instead of one.

## Aufgabe 2 (explanation)
Ausarbeitung is on the PDF.
Explanation:
1. The index the addr is stored at corresponds to the last (2) digits of the index, after that the entry is valid (for as long are there is an entry in that location).
2. The Tag corresponds to the FIRST two digits of the address.
3. The address is only stored when LOAD word is called, for store word it is not stored, only read from the cache if it is a hit. If it is not found in the cache during a `sw` call, the cache doesn't change and it is simply written to main memory.
4. If `sw` is called and it *is* found in the cache, then that entry is marked as dirty, and the storing of the data is delayed until that entry slot is needed for something else. **When dirty entry is finally pushed out, the write back happens.**
![[../../UEs/_attachments/Pasted image 20240630192159.png]]
## Aufgabe 3 (explanation)
Ausarbeitung is on the PDF.
Explanation:
An associative cache has no fixed mapping of addresses to cache slots. Each address is compared with all cache tags in parallel.
- If the cache is full and there it's a cache miss, it's called a capacity miss.
	- The solution is to replace an older entry using LRU, LFU or FIFO. (Least Recently/Least Frequently used, ...).
- Just check if it's a hit, if not, choose a slot for it depending on the algorithm used. ez
- For LRU, just see "how far you can go back" on each line before hitting an entry and choose the line that goes back the furthest (only works if you re-enter hit entries ofc)
- For LFU, if there are multiple entries with the same lowest number of uses (e.g. all 0, or all least used entries have had 1 use), then we just use LRU on those entries.

## Other types
![[_attachments/Pasted image 20240701210445.png]]
![[_attachments/Pasted image 20240701210504.png]]
