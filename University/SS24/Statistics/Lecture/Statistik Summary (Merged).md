---
type: university-lecture-note
lecture-note-course: "[[Lecture|University/SS24/Statistics/Lecture]]"
completion-status: Complete
---
# Index
- Einheit 1:
	- Grundbegriffe, Skalenniveaus, HÃ¤ufigkeiten
- Einheit 2
	- Mittel, Median, Quartile, Modus
- Einheit 3
	- StreuungsmaÃŸzahlen, Boxplot
- Einheit 4
	- Korrelation, Kovarianz, Korrelationskoeffizient, GÃ¼temaÃŸzahlen
- Einheit 5
	- Kombinatorik, Wege zur Wahrscheinlichkeit
- Einheit 6
	- Rechnen mit Wahrscheinlichkeiten
- Einheit 7
	- Wahrscheinlichkeits/-Verteilungsfunktion, Erwartungswert, Momente
- Einheit 8
	- Diskrete Verteilungen (binomial, bernoulli, hypergeometrisch, poisson, geometrisch, negativ binomial)
- Einheit 9
	- Stetige Verteilungen (Normalverteilung, Chi, t, F), Zusammenfassung
- Einheit 10
	- PunktschÃ¤tzÃ¼ng, BereichsschÃ¤tzung (Konfidenzintervalle (mittelwert, fÃ¼r einen Anteil))
- Einheit 11
	- Testen von Hypothesen





# Einheit 1
# Definitionen
## Grundbegriffe
**Empirische Grundgesamtheit:** Eine _endliche_ Menge von N Objekten, die rÃ¤umlich, zeitlich und sachlich abgegrenzt sind. 

**Merkmal:** dient der Klasseneinteilung der Grundgesamtheit in k Klassen. Die Zerlegung ist
- disjunkt
- vollstÃ¤ndig

**MerkmalsausprÃ¤gung ($x_i$):** charakteristische Eigenschaft der Elemente einer Grundgesamtheit.

**Parameter:** die "wahren Werte" einer Grundgesamtheit.

**Urliste:** unkomprimierte Aufzeichung aller MerkmalsauprÃ¤gungen der Elemente einer Grundgesamtheit. 

**Extensive Merkmale:** Merkmale, bei denene eine Summenbildung mÃ¶glich und sinnvoll wÃ¤re.

**Intensive Merkmale:**  Summenbildung ergibt keinen Sinn, erst die Durchschnittsbildung ist interpretierbar

## Skalenniveaus
**Nominal:** keine Beziehung zwischen Elementen einer Grundgesamtheit auÃŸer der Klasseneinteilung (bspw. Lieblingsfarben)

**Rangmerkmale:** "natÃ¼liche objektive" Ordnungsbeziehung (z.B. Schulnoten)

**Quantitativ:** ZÃ¤hl- oder Messprozesse
- diskret oder stetig

## HÃ¤ufigkeiten
**Absolut ($f_i$):** Anzahl de MerkmalsausprÃ¤gungen

**Relativ ($p_i$):** Prozentsatz der MerkmalsauprÃ¤gungen in einer Klasse

**Kumuliert ($F(x_i)$):** Anteil oder Anzahl, kumuliert... -> Empirische Verteilungsfunktion, CDF


# Einheit 2
# LagemaÃŸzahlen
## Mittelwert
- Nicht lageninvariant und nicht skaleninvariant, also ist der Mittelwert abhÃ¤ngig von lage und grÃ¶ÃŸe der Zahlen.
- Ohne Angabe einer Streuung nicht unbedingt aussagekrÃ¤ftig
### Arithmetischer Mittelwert
**bei gruppierten diskreten Daten:**
- $\bar x = \frac{1}{N} * \sum\limits^k_{i=1}f_i*x_i$ (absolute H. * AusprÃ¤gung)
- bzw. $\bar x = \sum\limits^k_{i=1}p_i*x_i$ (relative H. * AusprÃ¤gung)
**bei gruppierten stetigen Daten (Intervalle):**
- Es wird einfach nur der Mittelwert der Ober- und Untergrenze verwendet
### Geometrisches Mittel (Mittlerer Wachstumsfaktor):
Wird bei der Berechnung von "Wachstumsfaktoren" verwendet
	- Wachstumsfaktor: neuer Wert / alter WErt
	- Wachstumsrate: Wachstumsfaktor - 1

$\bar x_{geo} = \sqrt[3]{faktor_1*faktor_2*...*faktor_{n}} = \text{durchschnittlicher Wachstumsfaktor}$

### Harmonisches Mittel:
- Bei VerhÃ¤ltnisgrÃ¶ÃŸen
- Das arithmetische Mittel ist der kehrwert des harmonischen Mittelwertes der kehrwerte der einzelnen Werte.
- Example where this is necessary: Average speed driven on the same length path. Drove for longer on a slower speed, so the avg. should shift in that direction.

![[../Summaries - Copy/_attachments/Pasted image 20240626145845.png]]
### Gewogenes arithmetisches Mittel
â€¢ erlaubt Betonung einflussreicher Daten bzw. Reduzierung des Einflusses weniger wichtiger Daten

![[../Summaries - Copy/_attachments/Pasted image 20240626145830.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626145956.png]]
## Median
- AusreiÃŸer sind kein Problem
In Verteilungsfunktion: $F(\bar x)_{0.5} = 0.5$ (Kumulierte Haufigkeiten only ofc)

Bei gruppierten Daten gilt folgende Formel:

![[../Summaries - Copy/_attachments/Pasted image 20240626152258.png]]
### Tukey's Hinges
Aufteilung in 3 Quartile
- Median (Mittelwert der zwei mittleren Zahlen oder die zahl selber)
- Quartile: Mediane der Zwei HÃ¤lften
## Modus
- Der Modalwert xmod ist die MerkmalsausprÃ¤gung, die am hÃ¤ufigsten vorkommt (sprich der Wert mit der grÃ¶ÃŸten Wahrscheinlichkeit). 
- Falls mehrere AusprÃ¤gungen gleich hÃ¤ufig vorkommen, spricht man von einer multimodalen Verteilung (Gegenteil: unimodale Verteilung). 
- Bei einer Klasseneinteilung gilt: Klasse mit der grÃ¶ÃŸten HÃ¤ufigkeit = modale Klass


# Einheit 3
# StreuungsmaÃŸzahlen

## Spannweite, Interquartilsdistanz
Spannweite (â€Rangeâ€œ): Maximum â€“ Minimum
- Nachteil: Die Spannweite ignoriert alle Werte zwischen dem Minimum bzw. dem Maximum, hÃ¤ngt empfindlich von AusreiÃŸern ab und nÃ¼tzt die Daten nicht effizient aus.
Interquartilsdistanz (â€Interquartilrangeâ€œ): IQR = 3. Quartil â€“ 1. Quartil 
- Umgeht die AusreiÃŸer-Problematik teilweise
- Dennoch sind Spannweite und IQR nur grobe MaÃŸzahlen fÃ¼r die Streuung, da sie nur von 2 Werten abhÃ¤ngen
## Varianz
- Der Nachteil der Varianz ist die â€quadratische MaÃŸeinheitâ€œ und die â€quadratische Skalentransformationâ€œ.
### Empirische Varianz
- Wir gehen von empirisch erhobenen Daten aus
![[../Summaries - Copy/_attachments/Pasted image 20240626152922.png]]
bzw. nach Steiner
![[../Summaries - Copy/_attachments/Pasted image 20240626153903.png]]
### Stichprobenvarianz
- Wollen von einer Stichprobe auf die "Wahre" Varianz schlieÃŸen
![[../Summaries - Copy/_attachments/Pasted image 20240626154131.png]]
this only gains relevance in induktive statistik though, should stick to normal variance for the most part
### Varianz bei gruppierten Daten
![[../Summaries - Copy/_attachments/Pasted image 20240626154323.png]]
Just take the KlassenhÃ¤ufigkeit $f_i$ into account too and use the Klassenmitten for $x_i$
### Varianz (stetig)
![[../Summaries - Copy/_attachments/Pasted image 20240626185748.png]]
## Standardabweichung
- LÃ¶st die Probleme der Varianz
- $SD(x)= \sigma =\sqrt{Var(x)}$
## Variationskoeffizient, Empirische Schiefe/WÃ¶lbung
### Variationskoeffizient
- HÃ¤ngt nicht von MaÃŸeinheiten ab
- FÃ¼r Verteilungen mit unterschiedlichen MaÃŸeinheiten
- Streuung wird in relation zum Mittelwert gesetzt und in Prozent angegeben
- Eignet sich zum Vergleich von StreuungsverhÃ¤ltnissen
![[../Summaries - Copy/_attachments/Pasted image 20240626160928.png]]
### Empirische Schiefe/WÃ¶lbung
**Schiefe**
- Wie sehr die Verteilung nach links/rechts gewÃ¶lbt ist
![[../Summaries - Copy/_attachments/Pasted image 20240626161114.png]]

**WÃ¶lbung**
- hÃ¶he der "spitze" der Verteilung
![[../Summaries - Copy/_attachments/Pasted image 20240626161134.png]]
# Boxplot
- In a normal box plot, the line ends/whiskers are the max/min of the dataset
- in a modified boxplot, we can represent outliers too, but the ends are shifted... need to determine which one we use in advance
![[../Summaries - Copy/_attachments/Pasted image 20240626161420.png]]
An Extremwert would be represented by a tiny dot if it's beyond the Box edge $\pm 3*$box length




# Einheit 4
# Korrelation
## Kovarianz
- Vorrraussetzung: Es liegt eine bivariate (two variables) Grundgesamtheit mit den Datenreihen x und y vor.
- Eine Kennziffer zur Beschreibung der Art des Zusammenhangs der beiden Datenreihen
- Die Kovarianz ist eine nicht standardisierte MaÃŸzahl fÃ¼r den Zusammenhang zweier Datenreihen und gibt nur die Richtung eines Zusammenhangs an, nicht die StÃ¤rke des Zusammenhangs
- N ist die Anzahl an AusprÃ¤gungen pro Datensatz. Alles nach dem Summenzeichen sollte auch in klammern sein.
(nach Steiner, Empirisch)
![[../Summaries - Copy/_attachments/Pasted image 20240626162330.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626162335.png]]
Stichprobenkovarianz:
![[../Summaries - Copy/_attachments/Pasted image 20240626162354.png]]
## Korrelationskoeffizient
Ein Korrelationskoeffizient gibt die StÃ¤rke und Richtung des Zusammenhangs zweier Datenreihen an
- Voraussetzung: Es liegt eine bivariate Grundgesamtheit mit den Datenreihen x und y vor.
### Bravais-pearson
- Empirische Korrelationskoeffizient
- standardisiert und dimensionslos
- invariant gegenÃ¼ber linearen transformationen
- immer von -1 bis +1
![[../Summaries - Copy/_attachments/Pasted image 20240626162612.png]]
interpretation:
- Um so nÃ¤her der Betrag des Korrelationskoeffizienten bei 1 liegt, desto stÃ¤rker ist der Zusammenhang.\
- Bei einem Korrelationskoeffizienten von 0 liegt kein linearer Zusammenhang (â€unkorreliertâ€œ) vor. Es kann aber ein nicht-linearer (z.B.: quadratischer, â€¦) Zusammenhang bestehen
### Spearman
- auch von -1 bis +1
- Auf Grund seiner â€Rangnaturâ€œ misst er nicht den linearen Zusammenhang zweier Datenreihen sondern deren â€generelleâ€œ â€GleichlÃ¤ufigkeitâ€œ bzw. â€GegenlÃ¤ufigkeitâ€œ (Monotonieverhalten).

Interpretation: 
Es gilt:
- GleichlÃ¤ufigkeit (monoton steigend): groÃŸe x-Werte mit groÃŸen y-Werten
- GegenlÃ¤ufigkeit (monoton fallend): groÃŸe x-Werte mit kleinen y-Werten
- Bei +1 bzw. -1 liegt eine â€perfekteâ€œ GleichlÃ¤ufigkeit bzw. GegenlÃ¤ufigkeit vor.
- Bei 0 bzw. Werten nahe 0 besteht ein Zusammenhang, der nicht ausschlieÃŸlich gleichlÃ¤ufig bzw. gegenlÃ¤ufig ist\
Beispiel:
![[_attachments/Pasted image 20240627211142.png]]
Die Berechnung des Korrelationskoeffizienten $r_{xy}$  ist gleich wie bei den anderen.
# Regressionsrechnung
- Create a linear equation $\hat y_i$ to predict a value at a certain point between two variables
![[../Summaries - Copy/_attachments/Pasted image 20240626163943.png]]
## GÃ¼temaÃŸzahlen
- Das Regressionsmodell erklÃ¤rt die Streuung der abhÃ¤ngigen Variable Y. Wenn diese erklÃ¤rte Streuung hoch ist, liegt ein gutes Regressionsmodell vor.
- Die Streuung der Variable Y kann durch s.g. Quadratsummen (â€Sum of Squaresâ€œ) ausgedrÃ¼ckt werden.
 ![[../Summaries - Copy/_attachments/Pasted image 20240626164242.png]]
### Coefficient of determination
- Das VerhÃ¤ltnis von SQE und SQT kann als GÃ¼temaÃŸzahl verwendet werden und wird als BestimmtheitsmaÃŸ R2 (â€Coefficient of Determinationâ€œ) bezeichnet.
- Bei einem einfachen linearen Regressionsmodell entspricht das R2 dem quadrierten Bravais-Pearson-Korrelationskoeffizient der beiden Variablen.
- Es gilt: **Je grÃ¶ÃŸer das R2 ist, desto hÃ¶her ist die GÃ¼te des Regressionsmodells.**
- Das R2 gibt den Anteil der durch die Regression erklÃ¤rten Varianz der Variablen an. Damit ergibt sich ein Wertebereich von 0 bis 1.
- **Faustregel: ab 0,60 liegt ein brauchbares Modell vor**
![[../Summaries - Copy/_attachments/Pasted image 20240626164210.png]]


# Einheit 5
# Kombinatorik
## Permutation
**Definition:** Die n-stelligen Sequenzen (Pn), in denen jedes Element der Grundgesamtheit A1, A2, A3, â€¦ , An genau einmal vorkommt, nennt man Permutationen ohne Wiederholung aus n Zeichen.
-> AnordnungsmÃ¶glichkeiten
Ohne Wiederholung: ABC, CBA ...
![[../Summaries - Copy/_attachments/Pasted image 20240626164912.png]]
Mit Wiederholung:  ABBC, AABC
![[../Summaries - Copy/_attachments/Pasted image 20240626164959.png]]
#stichwÃ¶rter: "Auf wie viele Arten"...
## Kombination (nCr)
- n choose k, order in which we choose elements doesn't matter, only the "pool" of elements we get
- Always used when we think about the collection we have as a whole, not "ziehen" a certain hand. No action is involved, just existence (sounds like my life tbh).
Ohne Wiederholung:
![[../Summaries - Copy/_attachments/Pasted image 20240626165237.png]]
#stichwÃ¶rter: "wie viele verschiedene... gibt es"
Mit Wiederholung:
![[../Summaries - Copy/_attachments/Pasted image 20240626165303.png]]
#stichwÃ¶rter: "Wie viele Zusammensetzungen von... gibt es?"
## Variation
- n choose k, order in which we choose the elements does matter.
Ohne Wiederholung:
![[../Summaries - Copy/_attachments/Pasted image 20240626165646.png]]
#stichwÃ¶rter: "Wie viele MÃ¶glichkeiten..."
Mit Wiederholung:
![[../Summaries - Copy/_attachments/Pasted image 20240626165702.png]]
#stichwÃ¶rter:  "Wie viele MÃ¶glichkeiten... jeweils eine Ziffer von..."
# Wege zur Wahrscheinlichkeit
- Theoretische Wahrscheinlichkeit (â€Wahrscheinlichkeitsbegriff nach Laplaceâ€œ): Ableitung aus einer mathematischen Theorie und Erstellung eines Modells
- Empirische Wahrscheinlichkeit: Ableitung aus den Daten
- Subjektive â€Wahrscheinlichkeitâ€œ: Ableitung aus einer persÃ¶nlichen Meinung
- Bayesianische Wahrscheinlichkeit: Kombination von subjektiven Wahrscheinlichkeiten (â€prior-probabilitesâ€œ), einem Modell und den Daten
-


# Einheit 6
# Rechnen mit Wahrscheinlichkeiten
**Disjunkte Ereignisse**Â sind Ereignisse, die nicht gleichzeitig auftreten kÃ¶nnen, bspw. Tor: 30%, Tor: 40%. Wenn A und B disjunkt sind, dann kÃ¶nnen sie nicht gleichzeitig auftreten, und sind niemals unabhÃ¤ngig.
Bei additionsregel kÃ¶nnen ereignisse disjunkt sein? also $A \cap B = \{\}$. 
## UnabhÃ¤ngige Ereignisses
**UnabhÃ¤ngig:** Eintreten eines Ereignis beeinflusst das andere Ereignis
![[../Summaries - Copy/_attachments/Pasted image 20240626171923.png]]
## Bedingte Wahrscheinlichkeiten
![[../Summaries - Copy/_attachments/Pasted image 20240626171824.png]]
$P(A|B)= \frac{P(B|A)*P(A)}{P(B)}$
### Bayes
- P(A|B) bezeichnet die bedingte Wahrscheinlichkeit des Ereignisses A unter der Bedingung, dass B eingetreten ist (â€posteriori Wahrscheinlichkeitâ€œ).
![[../Summaries - Copy/_attachments/Pasted image 20240626172119.png]]


# Einheit 7
# Theorie der Zufallsvariablen
## Wahrscheinlichkeits-/Verteilungsfunktion
**Bei diskreten Zufallsvariablen**
Tablle aufstellen in denen jedes Ergebnis (bspw. Augenzahl) und die Wahrscheinlichkeit $f(x_i)$ notiert wird, Verteilungsfunktion $F(x_i)$ ist dann die Kumulative Wahrscheinlichkeit in der zweiten Spalte.

**Bei stetigen Zufallsvariablen**
Zur Wahrscheinlichkeitsfunktion hinzu kommt die Wahscheinlichkeits _dichte_. Dies ist einfach das Integral der Funktion.

FÃ¼r eine stetige Zufallsvariable X gilt:
![[../Summaries - Copy/_attachments/Pasted image 20240626173335.png]]
Zur bestimmung der Dichte muss man nicht $\pm\infty$ hernehmen, sondern nur den Bereich in dem die Wsl. nicht 0 ist, um den Ausdruck = 1 zu setzen.
## Erwartungswert
Bei einer diskreten Zufallsvariable
![[../Summaries - Copy/_attachments/Pasted image 20240626185139.png]]
Bei stetigen Zufallsvariable
![[../Summaries - Copy/_attachments/Pasted image 20240626185309.png]]
Der Erwartungswert einer stetigen Zufallsvariablen ist der â€Schwerpunkt" der FlÃ¤che unter der Dichtefunktion aus
### Momente von Zufallsvariablen
- Momente von Zufallsvariablen sind KenngrÃ¶ÃŸen, die zur Beschreibung einer Zufallsvariablen dienen.
- Momente sind als Erwartungswerte der Funktionen y = (x âˆ’ a)k definiert.
- FÃ¼r den Fall â€a = 0â€œ spricht man von gewÃ¶hnlichen Momenten und fÃ¼r den Fall â€a = E(X)â€œ von zentralen Momenten.
![[../Summaries - Copy/_attachments/Pasted image 20240626185532.png]]
- Der erste gewÃ¶hnliche Moment ist der Erwartungswert
- Der zweite zentrale Moment ist die Varianz
### Rechenregeln
![[../Summaries - Copy/_attachments/Pasted image 20240626185820.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626185937.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626190044.png]]



# Einheit 8
# Verteilung von Zufallsvariablen
## Diskrete Verteilungen
### Diskrete Gleichverteilung
AusprÃ¤gung fÃ¼r jedes X gleich, bspw. eine bestimmte nummer 1x wÃ¼rfeln -> Wsl. immer 1/6 bei einem normalen WÃ¼rfel.
![[../Summaries - Copy/_attachments/Pasted image 20240626190847.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626190929.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626190934.png]]
### Binomialverteilung
- Beschreibt Erfolge (Vorraussetzung "Erfolg" und "Misserfolg" als Ereignisse). 
- Die Erfolgswahrscheinlichkeit p ist fÃ¼r jeden Versuch gleich (also bspw. mit zurÃ¼cklegen)
![[../Summaries - Copy/_attachments/Pasted image 20240626191214.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626191219.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626191235.png]]
### Bernoulli-Verteilung
- Erfolg/Misserfolg als Vorraussetzung
- Versuch wird nur einmal durchgefÃ¼hrt
![[../Summaries - Copy/_attachments/Pasted image 20240626191500.png]]
- Die Bernoulli-Verteilung besitzt den Erwartungswert p und die Varianz pâ‹…(1 âˆ’ p).
- Eine Bernoulli-Kette (â€Bernoulli-Prozessâ€œ) besteht aus unabhÃ¤ngigen Bernoulli-Variablen mit jeweils identer Erfolgswahrscheinlichkeit p.
- Die Anzahl der Erfolge bei n Bernoulli-Variablen (= Bernoulli-Kette der LÃ¤nge n) folgt einer Binomialverteilung mit den Parametern n und p
### Hypergeometrische Verteilung
- "Ziehen" merhmals (n-mal), kein ZurÃ¼cklegen (bspw. rote und blaue kugeln)
- Wahrscheinlichkeitsverteilung der bspw. Anzahl an X roten kugeln nach n-mal ziehen (... beim Ziehen ohne ZurÃ¼cklegen von n Elementen (â€Stichprobeâ€œ) genau x Erfolge erzielt werden)
![[../Summaries - Copy/_attachments/Pasted image 20240626222018.png]]
### Poisson-Verteilung
- Ist ein Grenzfall der Binomialverteilung fÃ¼r unendlich viele Versuche (n â†’ âˆ) mit einer kleinen Erfolgswahrscheinlichkeit (p â†’ 0).
- Die Poisson-Verteilung kann zur Modellierung der Anzahl von (seltenen) Ereignissen verwendet werden, die bei einer konstanten mittleren Rate unabhÃ¤ngig voneinander in einem festen Zeitintervall oder rÃ¤umlichen Gebiet eintreten (â€Poisson-Prozessâ€œ).
![[../Summaries - Copy/_attachments/Pasted image 20240626222339.png]]
Bspw. bei N = 100 anwendbar
#stichwÃ¶rter 3000 Autos pro woche (n), 4 (p=4/3000) verkehrsunfÃ¤lle pro woche... approx. wsl, dass 7 unfÃ¤lle in einer woche stattfinden?. APPROXIMATIV
### Geometrische Verteilung
- â€Anzahl der Versuche bis zum ersten Erfolgâ€œ
- Vorraussetzung "Erfolg" und "Misserfolg"
![[../Summaries - Copy/_attachments/Pasted image 20240626222535.png]]
### Negative Binomialverteilung
- X â€Anzahl der Versuche bis zum k-ten Erfolgâ€œ
- Vorraussetzung "Erfolg" und "Misserfolg"
![[../Summaries - Copy/_attachments/Pasted image 20240626222631.png]]


# Einheit 9
# Stetige Verteilungen
## Normalverteilung
- Dichte ist symmetrisch um Âµ 
- Dichte hat das Maximum an der Stelle x = Âµ 
- Dichte strebt fÃ¼r x â†’ Â±âˆ gegen 0 
- Median entspricht dem Erwartungswert
### Dichte
![[../Summaries - Copy/_attachments/Pasted image 20240626223042.png]]
- Eine kleinere Varianz bedeutet eine "schmalere" Kurve
- Ã„nderungen des Mittelwerts Ã¤ndert die Lage
### Standardnormalverteilung
- $\mu = 0$ und $\sigma^2=1^2$
![[../Summaries - Copy/_attachments/Pasted image 20240626223432.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240626223453.png]]
### Sigma-Regel
![[../Summaries - Copy/_attachments/Pasted image 20240626223521.png]]
## Chi-Quadratverteilung
- Die Chi-Quadrat-Verteilung bildet die Basis des Chi-Quadrat-Tests, der u.a. beim statistischen Vergleich nominaler Daten eine wichtige Rolle spielt.
- Es wird ein Zufallsexperiment $Z_i$ mit standard-normalverteiltem Ausgang betrachtet.
- Dieses Zufallsexperiment wird n-mal unter gleichen Bedingungen unabhÃ¤ngig voneinander wiederholt. Damit erhÃ¤lt man die Zufallsvariablen Z1, Z2, â€¦ , Zn.
- Die Summe dieser quadrierten Zufallsvariablen folgt einer Chi-Quadratverteilung mit n Freiheitsgraden (â€Degrees of Freedomâ€œ).\
![[../Summaries - Copy/_attachments/Pasted image 20240626223942.png]]
## t-Verteilung
- Die t-Verteilung ist die Basis des t-Tests, der zur ÃœberprÃ¼fung dient, ob sich die Mittelwerte zweier Stichproben statistisch signifikant unterscheiden oder nicht.
- Es werden folgende zwei Zufallsexperimente Z und X betrachtet, wobei Z standardnormalverteilt und X Chi-Quadrat-verteilt mit n Freiheitsgraden ist.
- Damit ergibt sich unten stehende t-verteilte Zufallsvariable mit n Freiheitsgraden:
![[../Summaries - Copy/_attachments/Pasted image 20240626224729.png]]
## F-Verteilung
- Die F-Verteilung basiert auf dem Quotienten zweier Chi-Quadrat-verteilter Zufallsvariablen. Die F-Verteilung besitzt dadurch zwei unabhÃ¤ngige Freiheitsgrade m und n als Parameter.
- Bildet die Basis der Varianzanalyse
![[../Summaries - Copy/_attachments/Pasted image 20240626224839.png]]
## Zusammenfassung
Alle genannten Verteilungen spielen eine wichtige Rolle in der induktiven Statistik bzw. beim Testen (â€PrÃ¼fenâ€œ) von normalverteilten Daten. Daher werden diese Verteilungen oft auch PrÃ¼fverteilungen der Normalverteilung genannt.
![[../Summaries - Copy/_attachments/Pasted image 20240626224933.png]]
p... Wahrscheinlichkeit, mit der wir arbeiten wollen
# Zentraler Grenzwertsatz
- Zufallsvariablen lassen sich oft als Summen von Zufallsvariablen darstellen
	- bspw. das Gesamtgewicht eines Kartoffelsacks setzt sich aus der Summe der einzelnen Kartoffeln zusammen
**Der Erwartungswert der Summe ist** $E(S)=n*\mu$
**Die Varianz der Summe ist** $Var(S)=n*\sigma^2$
- Die n einzelnen Beobachtungen behalten ihre Verteilung bei, erst die Summe vieler einzelner Beobachtungen konvergiert zur Normalverteilung
- Strebt ab n > 30 gegen die Standardnormalverteilung
![[../Summaries - Copy/_attachments/Pasted image 20240626230040.png]]
### Grenzwertsatz nach Moivre-Laplace
- Approximation der diskreten Binomialverteilung durch die stetige Normalverteilung
- Vorraussetzung; $np(1-p)\ge 9$
![[../Summaries - Copy/_attachments/Pasted image 20240626230101.png]]
Die $\pm 0.5$ sind eine Verbesserung des normalen Moivre-laplace Satzes.


# Einheit 10
# Induktive Statistik
Eine reprÃ¤sentative Stichprobe weist (in bestimmten interessierenden Merkmalen) eine Ã¤hnliche Struktur wie die Grundgesamtheit auf.
Verfahren zur SchÃ¤tzung von Parametern werden anhand folgender Eigenschaften beurteilt: 
- PrÃ¤zision â€¦ Genauigkeit, mit der ein Ergebnis angegeben wird 
- ZuverlÃ¤ssigkeit â€¦ Wahrscheinlichkeit ein â€richtigesâ€œ Ergebnis zu erhalten
## PunktschÃ¤tzung
- Ein PunktschÃ¤tzer besitzt eine sehr hohe PrÃ¤zision. 
- Das Ergebnis entspricht einer konkreten, bestimmten Zahl. 
- Er ist einfach berechenbar und â€intuitivâ€œ verstÃ¤ndlich. 
- Der Nachteil ist seine geringe ZuverlÃ¤ssigkeit.
- Er kann als ein Punkt auf dem Zahlenstrahl identifiziert werden (â€Problem bei stetigen Merkmalenâ€œ)
**PunktschÃ¤tzer fÃ¼r erwartungswert und Varianz:**
![[../Summaries - Copy/_attachments/Pasted image 20240626230724.png]]
**PunktschÃ¤tzer fÃ¼r einen Anteil** $\pi$:
![[../Summaries - Copy/_attachments/Pasted image 20240626230801.png]]
### GÃ¼tekriterien fÃ¼r PunktschÃ¤tzer
Ein schÃ¤tzer ist **Erwartungstreu**, wenn der Erwartungswert dem tatsÃ¤chlichen Parameter entspricht.
Er ist **Konsistent**, wenn die Varianz des des SchÃ¤tzers immer kleiner wird, wenn der Stichprobenumfang steigt.
## BereichsschÃ¤tzung
- KonfidenzintervallschÃ¤tzung
- LÃ¤nge bzw. Breite $L$ (**PrÃ¤zision**)
- Hat eine beliebige **ZuverlÃ¤ssigkeit** von $S = 1-\alpha$
- $\alpha$ ist "das Risiko einer FehlschÃ¤tzung"
![[../Summaries - Copy/_attachments/Pasted image 20240626232256.png]]
### Konfidenzintervall fÃ¼r einen Mittelwert (bekanntes $\sigma$)
Voraussetzungen:
- unabhÃ¤ngige Zufallsstichprobe X = {x1, x2, â€¦ , xn} vom Umfang n 
- unbekannter Erwartungswert Âµ der Grundgesamtheit soll geschÃ¤tzt werden 
- die Varianz ÏƒÂ² der Grundgesamtheit ist bekannt 
- Stichprobe X bzw. der Mittelwert seien normalverteilt oder zumindest n > 30
$\mu \in \left[ \bar x \pm \phi^{-1}\left( 1-\frac{\alpha}{2} \right)* \frac{\sigma}{\sqrt{n}} \right]$
LÃ¤nge des Intervalls $L = 2 * \phi^{-1}\left( 1-\frac{\alpha}{2} \right) * \frac{\sigma}{\sqrt{n}}$
Stichprobenumfang $n = \left(2* \phi^{-1}\left( 1-\frac{\alpha}{2} \right) * \frac{\sigma}{L}\right)^2$
FÃ¼r ein einseitiges Konfidenzintervall betrachtet man dann entweder den mittelwert + oder - der rechten Seite der Formel.
### Konfidenzintervall fÃ¼r einen Mittelwert (unbekanntes $\sigma$)
Voraussetzungen:
- unabhÃ¤ngige Zufallsstichprobe X = {x1, x2, â€¦ , xn} vom Umfang n 
- unbekannter Erwartungswert Âµ der Grundgesamtheit soll geschÃ¤tzt werden 
- die Varianz ÏƒÂ² der Grundgesamtheit ist nicht bekannt 
- Stichprobe X bzw. der Mittelwert seien normalverteilt oder zumindest n > 30
s is also calculated by my GDC lol. Sx.
![[../Summaries - Copy/_attachments/Pasted image 20240626233633.png]]
$\mu \in [\bar x \pm t_{n-1,1-a/2} * \frac{s}{\sqrt{n}}]$
Stichprobenumfang $n \approx \left( 2*\phi^{-1}\left( 1-\frac{\alpha}{2} \right)* \frac{s}{L} \right)^2$
$S = D\left({\frac{L\sqrt{n}}{2s}}\right)$
### Konfidenzintervall fÃ¼r einen Anteil
- Wir wollen ein Konfidenzintervall fÃ¼r den Anteil ğœ‹ der Objekte mit der interessierenden Eigenschaft in der Grundgesamtheit bestimmen.
- $k$ Objekte in unserer Stichprobe besitzen die "Interessierende" Eigenschaft, $1-k$ Objekte nicht.
$p = \frac{k}{n}$
$\pi \in [p \pm \phi^{-1}\left( 1-\frac{\alpha}{2} \right) * \sqrt{\frac{p*(1-p)}{n}}]$



# Einheit 11
# Testen von Hypothesen
## Fehlerarten
### Fehler 1. Art ($\alpha$-Fehler)
Kurz: Ein Fehler 1. Art ist eine falsche positive Antwort
- FÃ¼r eine Entscheidung basierend auf Stichproben-Ergebnissen mÃ¼ssen wir die MÃ¶glichkeit einer falschen Antwort akzeptieren.
- Konkret: Die Schlussfolgerung, dass unterschiedlicher Proteingehalt im Futter zu unterschiedlicher Gewichtszunahme fÃ¼hrt, kann auch ein Fehlschluss sein.
- Anders formuliert: Bei der Stichprobe erhÃ¤lt man eine â€positiveâ€œ Antwort, aber in der Grundgesamtheit ist dies die falsche Antwort. â” falsch positive Antwort
- Man spricht dann vom so genannten Î±-Fehler oder Fehler 1. Art.
Beispiele:
- Irrtumswahrscheinlichkeit, Signifikanznievaue
### Fehler 2. Art ($\beta$-Fehler)]
Kurz: Ein Fehler 2. Art ist eine falsche negative Antwort
- Angenommen, Dr. X hat trotz der FÃ¼tterung mit unterschiedlichem Futter keinen Unterschied bei der Gewichtszunahme beobachtet. 
- Schlussfolgerung von Dr. X: â€Viel Protein im Futter bringt bei Ratten keine andere Gewichtszunahme als wenig Protein im Futter.â€œ Diese Schlussfolgerung kann aber ebenfalls ein Fehlschluss sein.
- Anders formuliert: Bei der Stichprobe erhÃ¤lt man eine â€negativeâ€œ Antwort, aber in der Grundgesamtheit ist dies die falsche Antwort. â” falsch negative Antwort
- Man spricht dann vom so genannten Î²-Fehler oder Fehler 2. Art.
## Parametrischer Signifikanztest
- Wir stellen zwei statements auf, H0, H1
- H1 trÃ¤gt die Beweislast (â€Unterschied vorhandenâ€œ)
- H0 ist das gegenteil unserer Behauptung (â€kein Unterschied vorhandenâ€œ)
- Wenn die Nullhypotehese nicht abgelehnt werden kann, wird die Behauptung nicht widerlegt noch nachgewiesen, da ein $\beta$-Fehler kann mit einem Signifikanztest nicht kontrolliert werden.
**Beispiel:**
Es soll bewiesen werden, dass sich as Durschnittsalter deutlich von 27 Jahren unterscheidet.
- $H_{0}: \mu \approx 27$
- $H_{1}: \mu \not\approx 27$
-> Konfidenzintervall Berechnen, wenn sich 27 nicht darin befindet kÃ¶nnen wir H0 ablehnen, ansonsten kÃ¶nnen wir H0 nicht ablehnen.
## GauÃŸ-Test (z-Test)
Voraussetzungen:
- unabhÃ¤ngige Zufallsstichprobe X = {x1, x2, â€¦ , xn} vom Umfang n 
- unbekannter Erwartungswert Âµ der Grundgesamtheit soll gegen einen Referenzwert Âµ0 getestet werden 
- die Varianz ÏƒÂ² der Grundgesamtheit ist bekannt 
-  Stichprobe X bzw. der Mittelwert seien normalverteilt oder zumindest n > 30
![[../Summaries - Copy/_attachments/Pasted image 20240627000857.png]]
where u is phi^-1
## Einstichproben-t-Test
Voraussetzungen:
- unabhÃ¤ngige Zufallsstichprobe X = {x1, x2, â€¦ , xn} vom Umfang n 
- unbekannter Erwartungswert Âµ der Grundgesamtheit soll gegen einen Referenzwert Âµ0 getestet werden 
- die Varianz ÏƒÂ² der Grundgesamtheit ist nicht bekannt 
-  Stichprobe X bzw. der Mittelwert seien normalverteilt oder zumindest n > 30
![[../Summaries - Copy/_attachments/Pasted image 20240627001040.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240627001129.png]]
## Hypothesen
![[../Summaries - Copy/_attachments/Pasted image 20240627001203.png]]
## Unverbundener Zweistichproben-t-Test
- 2 unabhÃ¤ngige Grundgesamtheiten
Voraussetzungen:
- unabhÃ¤ngige Zufallsstichprobe X = {x1, x2, â€¦ , xn} vom Umfang n 
- unabhÃ¤ngige Zufallsstichprobe Y = {y1, y2, â€¦ , ym} vom Umfang m 
- X und Y sind unverbunden, d.h. sie hÃ¤ngen nicht voneinander ab 
- **VarianzhomogenitÃ¤t: Die Varianz ÏƒÂ² sei in den beiden Grundgesamtheiten gleich groÃŸ, aber unbekannt** ($\sigma^2 = \sigma^2_Y=\sigma^2_X$) 
- Stichproben bzw. Mittelwerte sind jeweils normalverteilt (ab einem Stichprobenumfang n > 30 greift der Zentrale Grenzwertsatz und man kann in diesem Fall sehr oft von einer annÃ¤hernden Normalverteilung ausgehen)

Wir mÃ¼ssen den **gepoolten** **VarianzschÃ¤tzer** nehmen
![[../Summaries - Copy/_attachments/Pasted image 20240627004419.png]]
**Konfidenzintervall der Mittelwertsdifferenz**
![[../Summaries - Copy/_attachments/Pasted image 20240627004505.png]]
![[../Summaries - Copy/_attachments/Pasted image 20240627004543.png]]
## p-Wert
Der konkrete Fehler 1. Art der "Datensituation"
- Der p-Wert ist (vereinfacht gesagt) die Wahrscheinlichkeit, das aktuelle Ergebnis (oder ein noch extremeres Ergebnis) zu erhalten, wenn die Nullhypothese richtig sei.
- Der p-Wert ist somit eine Art von â€bedingter Wahrscheinlichkeitâ€œ mit der Bedingung der angenommenen GÃ¼ltigkeit der Nullhypothese.
- Ist der errechnete p-Wert kleiner oder gleich dem Signifikanzniveau (Fehler 1. Art) dann wird die Nullhypothese abgelehnt und das Ergebnis als statistisch signifikant bezeichnet.
- Vorteile: direkter Vergleich mit dem Signifikanzniveau mÃ¶glich, ein MaÃŸ der Evidenz mit der eine Stichprobe fÃ¼r oder gegen die Nullhypothese spricht, einfache Datenexploration mÃ¶glich
- Nachteil: hÃ¤ndische Berechnung kaum mÃ¶glich, â€Fishing for Significanceâ€œ
The closer to 0 it is, the stronger the evidence against the null hypothesis (under 0.01 or so)
## Entscheidung fÃ¼r einen geeigneten Test
### Test auf HomoskedatizitÃ¤t
![[../Summaries - Copy/_attachments/Pasted image 20240627004831.png]]
H0 kann nicht abgelehnt werden -> Zweistichproben-t-test
sonst -> Welch
## Welch's Test
![[../Summaries - Copy/_attachments/Pasted image 20240627005026.png]]
## Gepaarter t-test
- Wenn eine Stichprobe zweimal untersucht wird
- FÃ¼r den Vergleich von Mittelwerten zweier verbundener Messung einer Grundgesamtheiten kann der gepaarte t-Test verwendet werden.
![[../Summaries - Copy/_attachments/Pasted image 20240627005310.png]]
## Multiples Testen
- In einer Studie wird in der Regel aber nicht nur eine einzelne Hypothese betrachtet, sondern mehrere Hypothesen. Jeder einzelne Test, der auf einem Signifikanzniveau von Î± = 5% durchgefÃ¼hrt wird, hat eine Irrtumswahrscheinlichkeit von 5% â” bei 100 DurchfÃ¼hrungen liefern durchschnittlich 5 Tests ein â€falsch signifikantesâ€œ Ergebnis â€¢ 
- Vergleicht man den p-Wert jedes einzelnen Tests weiterhin mit Î±, so irrt man sich bei jeder Aussage mit der Wahrscheinlichkeit Î± â” in der Summe der Tests steigt dadurch die Wahrscheinlichkeit mindestens einer Falschaussage dramatisch an. Man spricht dann von einem s.g. â€multiplen Testproblemâ€œ.
- Durch multiples Testen kommt es zu einer Inflation des Fehlers 1. Art. Sprich, je mehr Hypothesen man testet, desto hÃ¶her wird die Wahrscheinlichkeit, dass eine davon (fÃ¤lschlicherweise) abgelehnt wird.
![[../Summaries - Copy/_attachments/Pasted image 20240627005418.png]]
